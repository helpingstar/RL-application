{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"mount_file_id":"1YTNRGtCizAQl5LbKZopJuOsutvatYqNm","authorship_tag":"ABX9TyPsQPK6BQm+hsTENrBVHWFa"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"gpuClass":"standard"},"cells":[{"cell_type":"code","execution_count":1,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"BzCbH5mXNPY4","executionInfo":{"status":"ok","timestamp":1673431338044,"user_tz":-540,"elapsed":45938,"user":{"displayName":"HS","userId":"14086807755961934596"}},"outputId":"d1cbd3ce-3ca6-44b5-a3ba-65708e0221e9"},"outputs":[{"output_type":"stream","name":"stdout","text":["\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m879.1/879.1 KB\u001b[0m \u001b[31m18.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.0/2.0 MB\u001b[0m \u001b[31m26.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m174.3/174.3 KB\u001b[0m \u001b[31m17.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m184.0/184.0 KB\u001b[0m \u001b[31m16.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m62.7/62.7 KB\u001b[0m \u001b[31m6.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m140.6/140.6 KB\u001b[0m \u001b[31m13.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25h  Building wheel for pathtools (setup.py) ... \u001b[?25l\u001b[?25hdone\n","\u001b[34m\u001b[1mwandb\u001b[0m: Logging into wandb.ai. (Learn how to deploy a W&B server locally: https://wandb.me/wandb-server)\n","\u001b[34m\u001b[1mwandb\u001b[0m: You can find your API key in your browser here: https://wandb.ai/authorize\n","\u001b[34m\u001b[1mwandb\u001b[0m: Paste an API key from your profile and hit enter, or press ctrl+c to quit: \n","\u001b[34m\u001b[1mwandb\u001b[0m: Appending key for api.wandb.ai to your netrc file: /root/.netrc\n"]}],"source":["!pip install gymnasium -q\n","!pip install tensorboard -q\n","!pip install wandb -q\n","!wandb login"]},{"cell_type":"code","source":["# b01af515b5a35d1f0b9fbaecfff35d74e4fd8b1e"],"metadata":{"id":"tbu0IaU3NgiS","executionInfo":{"status":"ok","timestamp":1673431338044,"user_tz":-540,"elapsed":6,"user":{"displayName":"HS","userId":"14086807755961934596"}}},"execution_count":2,"outputs":[]},{"cell_type":"code","source":["!git clone https://github.com/helpingstar/gym-snakegame.git\n","%cd gym-snakegame\n","!pip install -r requirements.txt\n","!pip install -e ."],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"0RiA1oWsNhhP","executionInfo":{"status":"ok","timestamp":1673431361003,"user_tz":-540,"elapsed":22964,"user":{"displayName":"HS","userId":"14086807755961934596"}},"outputId":"71da36cf-7be1-458b-9ced-832321f9e861"},"execution_count":3,"outputs":[{"output_type":"stream","name":"stdout","text":["Cloning into 'gym-snakegame'...\n","remote: Enumerating objects: 62, done.\u001b[K\n","remote: Counting objects: 100% (62/62), done.\u001b[K\n","remote: Compressing objects: 100% (46/46), done.\u001b[K\n","remote: Total 62 (delta 22), reused 53 (delta 15), pack-reused 0\u001b[K\n","Unpacking objects: 100% (62/62), done.\n","/content/gym-snakegame\n","Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n","Requirement already satisfied: gymnasium>=0.26.2 in /usr/local/lib/python3.8/dist-packages (from -r requirements.txt (line 1)) (0.27.0)\n","Collecting pygame==2.1.0\n","  Downloading pygame-2.1.0-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (18.3 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m18.3/18.3 MB\u001b[0m \u001b[31m58.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting moviepy>=1.0.3\n","  Downloading moviepy-1.0.3.tar.gz (388 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m388.3/388.3 KB\u001b[0m \u001b[31m30.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n","Requirement already satisfied: numpy>=1.18.0 in /usr/local/lib/python3.8/dist-packages (from -r requirements.txt (line 4)) (1.21.6)\n","Requirement already satisfied: gymnasium-notices>=0.0.1 in /usr/local/lib/python3.8/dist-packages (from gymnasium>=0.26.2->-r requirements.txt (line 1)) (0.0.1)\n","Requirement already satisfied: importlib-metadata>=4.8.0 in /usr/local/lib/python3.8/dist-packages (from gymnasium>=0.26.2->-r requirements.txt (line 1)) (6.0.0)\n","Requirement already satisfied: jax-jumpy>=0.2.0 in /usr/local/lib/python3.8/dist-packages (from gymnasium>=0.26.2->-r requirements.txt (line 1)) (0.2.0)\n","Requirement already satisfied: shimmy<1.0,>=0.1.0 in /usr/local/lib/python3.8/dist-packages (from gymnasium>=0.26.2->-r requirements.txt (line 1)) (0.2.0)\n","Requirement already satisfied: cloudpickle>=1.2.0 in /usr/local/lib/python3.8/dist-packages (from gymnasium>=0.26.2->-r requirements.txt (line 1)) (2.2.0)\n","Requirement already satisfied: typing-extensions>=4.3.0 in /usr/local/lib/python3.8/dist-packages (from gymnasium>=0.26.2->-r requirements.txt (line 1)) (4.4.0)\n","Requirement already satisfied: decorator<5.0,>=4.0.2 in /usr/local/lib/python3.8/dist-packages (from moviepy>=1.0.3->-r requirements.txt (line 3)) (4.4.2)\n","Requirement already satisfied: tqdm<5.0,>=4.11.2 in /usr/local/lib/python3.8/dist-packages (from moviepy>=1.0.3->-r requirements.txt (line 3)) (4.64.1)\n","Requirement already satisfied: requests<3.0,>=2.8.1 in /usr/local/lib/python3.8/dist-packages (from moviepy>=1.0.3->-r requirements.txt (line 3)) (2.25.1)\n","Collecting proglog<=1.0.0\n","  Downloading proglog-0.1.10-py3-none-any.whl (6.1 kB)\n","Requirement already satisfied: imageio<3.0,>=2.5 in /usr/local/lib/python3.8/dist-packages (from moviepy>=1.0.3->-r requirements.txt (line 3)) (2.9.0)\n","Collecting imageio_ffmpeg>=0.2.0\n","  Downloading imageio_ffmpeg-0.4.8-py3-none-manylinux2010_x86_64.whl (26.9 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m26.9/26.9 MB\u001b[0m \u001b[31m28.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: pillow in /usr/local/lib/python3.8/dist-packages (from imageio<3.0,>=2.5->moviepy>=1.0.3->-r requirements.txt (line 3)) (7.1.2)\n","Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.8/dist-packages (from importlib-metadata>=4.8.0->gymnasium>=0.26.2->-r requirements.txt (line 1)) (3.11.0)\n","Requirement already satisfied: chardet<5,>=3.0.2 in /usr/local/lib/python3.8/dist-packages (from requests<3.0,>=2.8.1->moviepy>=1.0.3->-r requirements.txt (line 3)) (4.0.0)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.8/dist-packages (from requests<3.0,>=2.8.1->moviepy>=1.0.3->-r requirements.txt (line 3)) (2022.12.7)\n","Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.8/dist-packages (from requests<3.0,>=2.8.1->moviepy>=1.0.3->-r requirements.txt (line 3)) (2.10)\n","Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.8/dist-packages (from requests<3.0,>=2.8.1->moviepy>=1.0.3->-r requirements.txt (line 3)) (1.26.13)\n","Building wheels for collected packages: moviepy\n","  Building wheel for moviepy (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for moviepy: filename=moviepy-1.0.3-py3-none-any.whl size=110742 sha256=33d70f88a4d7f8c75e2a4756723e902ad6e4a571e2ce9d229078a766da819b88\n","  Stored in directory: /root/.cache/pip/wheels/e4/a4/db/0368d3a04033da662e13926594b3a8cf1aa4ffeefe570cfac1\n","Successfully built moviepy\n","Installing collected packages: pygame, proglog, imageio_ffmpeg, moviepy\n","  Attempting uninstall: moviepy\n","    Found existing installation: moviepy 0.2.3.5\n","    Uninstalling moviepy-0.2.3.5:\n","      Successfully uninstalled moviepy-0.2.3.5\n","Successfully installed imageio_ffmpeg-0.4.8 moviepy-1.0.3 proglog-0.1.10 pygame-2.1.0\n","Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n","Obtaining file:///content/gym-snakegame\n","  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n","Requirement already satisfied: gymnasium>=0.26.0 in /usr/local/lib/python3.8/dist-packages (from gym-snakegame==0.0.1) (0.27.0)\n","Requirement already satisfied: pygame==2.1.0 in /usr/local/lib/python3.8/dist-packages (from gym-snakegame==0.0.1) (2.1.0)\n","Requirement already satisfied: gymnasium-notices>=0.0.1 in /usr/local/lib/python3.8/dist-packages (from gymnasium>=0.26.0->gym-snakegame==0.0.1) (0.0.1)\n","Requirement already satisfied: shimmy<1.0,>=0.1.0 in /usr/local/lib/python3.8/dist-packages (from gymnasium>=0.26.0->gym-snakegame==0.0.1) (0.2.0)\n","Requirement already satisfied: importlib-metadata>=4.8.0 in /usr/local/lib/python3.8/dist-packages (from gymnasium>=0.26.0->gym-snakegame==0.0.1) (6.0.0)\n","Requirement already satisfied: numpy>=1.21.0 in /usr/local/lib/python3.8/dist-packages (from gymnasium>=0.26.0->gym-snakegame==0.0.1) (1.21.6)\n","Requirement already satisfied: jax-jumpy>=0.2.0 in /usr/local/lib/python3.8/dist-packages (from gymnasium>=0.26.0->gym-snakegame==0.0.1) (0.2.0)\n","Requirement already satisfied: typing-extensions>=4.3.0 in /usr/local/lib/python3.8/dist-packages (from gymnasium>=0.26.0->gym-snakegame==0.0.1) (4.4.0)\n","Requirement already satisfied: cloudpickle>=1.2.0 in /usr/local/lib/python3.8/dist-packages (from gymnasium>=0.26.0->gym-snakegame==0.0.1) (2.2.0)\n","Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.8/dist-packages (from importlib-metadata>=4.8.0->gymnasium>=0.26.0->gym-snakegame==0.0.1) (3.11.0)\n","Installing collected packages: gym-snakegame\n","  Running setup.py develop for gym-snakegame\n","Successfully installed gym-snakegame-0.0.1\n"]}]},{"cell_type":"code","source":["import gymnasium as gym\n","import torch.nn as nn\n","import wandb\n","import time\n","import torch\n","import torch.optim as optim\n","import random\n","from tqdm import tqdm\n","import numpy as np\n","import torch.nn.functional as F\n","import gym_snakegame\n","from torch.utils.tensorboard import SummaryWriter"],"metadata":{"id":"GTymHzOuNioH","executionInfo":{"status":"ok","timestamp":1673431367294,"user_tz":-540,"elapsed":6312,"user":{"displayName":"HS","userId":"14086807755961934596"}}},"execution_count":4,"outputs":[]},{"cell_type":"code","source":["import numpy as np\n","from typing import Dict\n","from gymnasium import spaces\n","\n","def obs_space_to_shape(obs_space: spaces.Space):\n","    if isinstance(obs_space, spaces.Box):\n","        return obs_space.shape\n","    if isinstance(obs_space, spaces.Discrete):\n","        return (1,)\n","\n","    else:\n","        raise NotImplementedError(f\"{obs_space} observation space is not supported\")\n","\n","class ReplayBuffer:\n","    \"\"\"A simple numpy replay buffer.\"\"\"\n","\n","    def __init__(self, obs_space:spaces.Space , size: int, batch_size: int = 32):\n","        self.max_size, self.batch_size = size, batch_size\n","        self.obs_shape = obs_space_to_shape(obs_space)\n","        self.obs_buf = np.zeros((size,) + self.obs_shape, dtype=np.float32)\n","        self.next_obs_buf = np.zeros((size,) + self.obs_shape, dtype=np.float32)\n","        self.acts_buf = np.zeros([size], dtype=np.float32)\n","        self.rews_buf = np.zeros([size], dtype=np.float32)\n","        self.done_buf = np.zeros(size, dtype=np.float32)\n","        self.ptr, self.size, = 0, 0\n","\n","    def store(\n","        self,\n","        obs: np.ndarray,\n","        act: np.ndarray,\n","        rew: float,\n","        next_obs: np.ndarray,\n","        done: bool,\n","    ):\n","        self.obs_buf[self.ptr] = obs\n","        self.next_obs_buf[self.ptr] = next_obs\n","        self.acts_buf[self.ptr] = act\n","        self.rews_buf[self.ptr] = rew\n","        self.done_buf[self.ptr] = done\n","        self.ptr = (self.ptr + 1) % self.max_size\n","        self.size = min(self.size + 1, self.max_size)\n","\n","    def sample_batch(self) -> Dict[str, np.ndarray]:\n","        idxs = np.random.choice(self.size, size=self.batch_size, replace=False)\n","        return dict(obs=self.obs_buf[idxs],\n","                    next_obs=self.next_obs_buf[idxs],\n","                    acts=self.acts_buf[idxs],\n","                    rews=self.rews_buf[idxs],\n","                    done=self.done_buf[idxs])\n","\n","    def __len__(self) -> int:\n","        return self.size\n","\n","\n","class AddChannelDimension(gym.ObservationWrapper):\n","    \"\"\"Image shape to num_channels x height x width\"\"\"\n","\n","    def __init__(self, env):\n","        super(AddChannelDimension, self).__init__(env)\n","        shape = self.observation_space.shape\n","        self.observation_space = gym.spaces.Box(low=0, high=5, shape=(1, shape[0], shape[1]))\n","\n","    def observation(self, observation):\n","        shape = observation.shape\n","        return observation.reshape(1, shape[0], shape[1])\n","\n","class DivideObservation(gym.ObservationWrapper):\n","    def __init__(self, env, divide=1.0):\n","        super().__init__(env)\n","        self.divide = divide\n","\n","    def observation(self, obs):\n","        return obs / self.divide\n","\n","class RewardModifier(gym.RewardWrapper):\n","    def __init__(self, env):\n","        gym.RewardWrapper.__init__(self, env)\n","\n","    def reward(self, reward):\n","        if reward == 0:\n","            return -0.5\n","        return reward * 20"],"metadata":{"id":"BtfNT9gMNjtf","executionInfo":{"status":"ok","timestamp":1673431367294,"user_tz":-540,"elapsed":7,"user":{"displayName":"HS","userId":"14086807755961934596"}}},"execution_count":5,"outputs":[]},{"cell_type":"code","source":["args = {\n","    'env_id': 'gym_snakegame/SnakeGame-v0',\n","    'env_id_short' : 'SnakeGame-v0',\n","    'seed': 42,\n","    'cuda': True,\n","    'learning_rate' : 0.003,\n","    'buffer_size' : 60000,\n","    'total_timesteps' : 8000000,\n","    'start_e' : 0.05, \n","    'end_e' : 0.01, \n","    'exploration_fraction' : 0.5,\n","    'wandb_project_name' : \"dqn-Snakegame\",\n","    'wandb_entity' : None,\n","    'learning_starts' : 60000,\n","    'train_frequency' : 1,\n","    'batch_size' : 256,\n","    'target_network_frequency' : 500,\n","    'gamma' : 0.95,\n","    'capture_video' : False,\n","    }\n","\n","device = torch.device(\"cuda\" if torch.cuda.is_available() and args[\"cuda\"] else \"cpu\")\n","print(device)\n","run_name=f\"{args['env_id_short']}_{args['seed']}_{int(time.time())}\""],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"42AKh27ENkxI","executionInfo":{"status":"ok","timestamp":1673431367294,"user_tz":-540,"elapsed":6,"user":{"displayName":"HS","userId":"14086807755961934596"}},"outputId":"56277fa9-cf63-49f3-8cfc-848730702b41"},"execution_count":6,"outputs":[{"output_type":"stream","name":"stdout","text":["cpu\n"]}]},{"cell_type":"code","source":["# input.shape : (5, 5)\n","class DQN(nn.Module):\n","    def __init__(self, env):\n","        super().__init__()\n","        self.network = nn.Sequential(\n","            nn.Linear(in_features=env.observation_space.shape[0], out_features=512),\n","            nn.ReLU(),\n","            nn.Linear(in_features=512, out_features=env.action_space.n)\n","        )\n","\n","    def forward(self, x):\n","        return self.network(x)"],"metadata":{"id":"LkrHyDW4NzF4","executionInfo":{"status":"ok","timestamp":1673431367295,"user_tz":-540,"elapsed":6,"user":{"displayName":"HS","userId":"14086807755961934596"}}},"execution_count":7,"outputs":[]},{"cell_type":"code","source":["def linear_schedule(start_e: float, end_e:float, duration: int, t: int):\n","    slope = (end_e - start_e) / duration\n","    return max(slope * t + start_e, end_e)"],"metadata":{"id":"OOUCCYUoN0PI","executionInfo":{"status":"ok","timestamp":1673431367764,"user_tz":-540,"elapsed":474,"user":{"displayName":"HS","userId":"14086807755961934596"}}},"execution_count":8,"outputs":[]},{"cell_type":"code","source":["env = gym.make(args['env_id'], size=5, n_target=1, render_mode='rgb_array')\n","env = gym.wrappers.RecordVideo(env, f\"/content/drive/MyDrive/RL/snakegame/video/{run_name}\", \n","                               episode_trigger=lambda x: x % 200 == 0,\n","                               name_prefix=run_name,\n","                               disable_logger=True)\n","env = AddChannelDimension(env)\n","env = RewardModifier(env)\n","env = DivideObservation(env, 5.0)\n","env = gym.wrappers.FlattenObservation(env)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"7tlAHBoSN1Tw","executionInfo":{"status":"ok","timestamp":1673431367765,"user_tz":-540,"elapsed":5,"user":{"displayName":"HS","userId":"14086807755961934596"}},"outputId":"3532b830-5f48-46a8-924f-c4b3d9584fb4"},"execution_count":9,"outputs":[{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.8/dist-packages/gymnasium/utils/passive_env_checker.py:35: UserWarning: \u001b[33mWARN: A Box observation space has an unconventional shape (neither an image, nor a 1D vector). We recommend flattening the observation to have only a 1D vector or use a custom policy to properly process the data. Actual observation shape: (5, 5)\u001b[0m\n","  logger.warn(\n"]}]},{"cell_type":"code","source":["# wandb.tensorboard.patch(root_logdir='runs')\n","wandb.init(\n","    # set the wandb project where this run will be logged\n","    name=run_name,\n","    project=args['wandb_project_name'],\n","    entity=args['wandb_entity'],\n","    # sync_tensorboard=True,\n","    config=args,\n","    monitor_gym=True,\n","    save_code=True\n",")\n","\n","writer = SummaryWriter(f'/content/drive/MyDrive/RL/snakegame/tensorboard/runs/{run_name}')\n","writer.add_text(\n","    \"hyperparameters\",\n","    \"|param|value|\\n|-|-|\\n%s\" % (\"\\n\".join([f\"|{key}|{value}|\" for key, value in args.items()])),\n",")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":142},"id":"4i-pIL71N2aA","executionInfo":{"status":"ok","timestamp":1673431378756,"user_tz":-540,"elapsed":10994,"user":{"displayName":"HS","userId":"14086807755961934596"}},"outputId":"a40b424a-a7e4-4636-fe50-982f6ef5b1c8"},"execution_count":10,"outputs":[{"output_type":"stream","name":"stderr","text":["ERROR:wandb.jupyter:Failed to detect the name of this notebook, you can set it manually with the WANDB_NOTEBOOK_NAME environment variable to enable code saving.\n","\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33miamhelpingstar\u001b[0m. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"]},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["Tracking run with wandb version 0.13.8"]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["Run data is saved locally in <code>/content/gym-snakegame/wandb/run-20230111_100251-mse2qlcf</code>"]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["Syncing run <strong><a href=\"https://wandb.ai/iamhelpingstar/dqn-Snakegame/runs/mse2qlcf\" target=\"_blank\">SnakeGame-v0_42_1673431369</a></strong> to <a href=\"https://wandb.ai/iamhelpingstar/dqn-Snakegame\" target=\"_blank\">Weights & Biases</a> (<a href=\"https://wandb.me/run\" target=\"_blank\">docs</a>)<br/>"]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":[" View project at <a href=\"https://wandb.ai/iamhelpingstar/dqn-Snakegame\" target=\"_blank\">https://wandb.ai/iamhelpingstar/dqn-Snakegame</a>"]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":[" View run at <a href=\"https://wandb.ai/iamhelpingstar/dqn-Snakegame/runs/mse2qlcf\" target=\"_blank\">https://wandb.ai/iamhelpingstar/dqn-Snakegame/runs/mse2qlcf</a>"]},"metadata":{}}]},{"cell_type":"code","source":["q_network = torch.load('/content/drive/MyDrive/RL/snakegame/weight/q_network_SnakeGame-v0_42_1673368645.pt').to(device)\n","optimizer = optim.Adam(q_network.parameters(), lr=args['learning_rate'])\n","target_network = DQN(env).to(device)\n","target_network.load_state_dict(q_network.state_dict())"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"eY2Rv4n0P1O-","executionInfo":{"status":"ok","timestamp":1673431380292,"user_tz":-540,"elapsed":1549,"user":{"displayName":"HS","userId":"14086807755961934596"}},"outputId":"754b20d9-e178-42e7-d48d-403552015adf"},"execution_count":11,"outputs":[{"output_type":"execute_result","data":{"text/plain":["<All keys matched successfully>"]},"metadata":{},"execution_count":11}]},{"cell_type":"code","source":["q_network = DQN(env).to(device)\n","optimizer = optim.Adam(q_network.parameters(), lr=args['learning_rate'])\n","target_network = DQN(env).to(device)\n","target_network.load_state_dict(q_network.state_dict())\n","\n","rb = ReplayBuffer(\n","    env.observation_space,\n","    args['buffer_size'],\n","    args['batch_size']\n",")\n","\n","start_time = time.time()\n","\n","obs, _ = env.reset()\n","score = 0\n","episode_cnt = 0\n","for global_step in tqdm(range(args['total_timesteps'])):\n","    epsilon = linear_schedule(args['start_e'], \n","                              args['end_e'], \n","                              args['exploration_fraction'] * args['total_timesteps'], \n","                              global_step)\n","    if random.random() < epsilon:\n","        action = env.action_space.sample()\n","    else:\n","        q_values = q_network(torch.Tensor(obs).to(device))\n","        action = torch.argmax(q_values).item()\n","    \n","    next_obs, reward, terminate, truncate, info = env.step(action)\n","    rb.store(obs, action, reward, next_obs, terminate)\n","    \n","    obs = next_obs\n","    score += reward \n","    \n","    if terminate:\n","        obs, _ = env.reset()\n","        writer.add_scalar(\"charts/episodic_return\", score, global_step)\n","        wandb.log({\"charts/episodic_return\": score}, step=global_step)\n","        score = 0\n","        episode_cnt += 1\n","        \n","    writer.add_scalar(\"charts/epsilon\", epsilon, global_step)\n","    wandb.log({\"charts/epsilon\": epsilon}, step=global_step)\n","    \n","    if global_step > args['learning_starts']:\n","        if global_step % args['train_frequency'] == 0:\n","            \n","            samples = rb.sample_batch()\n","            states = torch.FloatTensor(samples['obs']).to(device)\n","            next_states = torch.FloatTensor(samples['next_obs']).to(device)\n","            actions = torch.LongTensor(samples['acts']).reshape(-1, 1).to(device)\n","            rewards = torch.FloatTensor(samples['rews']).reshape(-1, 1).to(device)\n","            dones = torch.FloatTensor(samples[\"done\"].reshape(-1, 1)).to(device)\n","            \n","            with torch.no_grad():\n","                target_max, _ = target_network(next_states).max(dim=1)\n","                td_target = rewards.flatten() + args['gamma'] * target_max * (1 - dones.flatten())\n","            old_val = q_network(states).gather(1, actions).squeeze()\n","            loss = F.mse_loss(td_target, old_val)\n","            \n","            if global_step % 100 == 0:\n","                writer.add_scalar(\"losses/td_loss\", loss, global_step)\n","                writer.add_scalar(\"losses/q_values\", old_val.mean().item(), global_step)\n","                writer.add_scalar(\"charts/SPS\", int(global_step / (time.time() - start_time)), global_step)\n","                \n","                wandb.log({\"losses/td_loss\": loss, \"losses/q_values\": old_val.mean().item()}, step=global_step)\n","                wandb.log({\"charts/SPS\" : int(global_step / (time.time() - start_time))}, step=global_step)\n","            # optimize the model \n","            optimizer.zero_grad()\n","            loss.backward()  \n","            optimizer.step()\n","        \n","        # update the target network\n","        if global_step % args['target_network_frequency'] == 0:\n","            target_network.load_state_dict(q_network.state_dict())\n","env.close()\n","writer.close()\n","wandb.finish()"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"0I8iiGwiN39I","outputId":"cc68b5c8-dd3a-4bd1-b97c-3845032ebe4e"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stderr","text":[" 28%|██▊       | 2238699/8000000 [4:25:54<11:00:45, 145.32it/s]"]}]}]}